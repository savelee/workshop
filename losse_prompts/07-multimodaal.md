# Huiswerk: Multimodale LLM's

## Uitleg: Multimodale taalmodellen
Taalmodellen worden steeds slimmer! Ze kunnen niet alleen goed met taal overweg, maar beginnen ook naar beelden te kijken en te begrijpen. Dat noemen we Multimodale taalmodellen. Ze combineren taal en beeld, waardoor ze nog veel meer kunnen dan voorheen.

### Hoe werkt het?
In plaats van alleen tekst te geven, kun je een Multimodaal taalmodel ook een afbeelding laten zien. Het taalmodel kan dan de afbeelding analyseren en er iets over vertellen, of er zelfs op reageren. Je kunt het zien als een slimme computer die niet alleen leest, maar ook kijkt! Daarnaast is het mogelijk om de computer zelf plaatjes te tekenen!

### Waarom is het handig?
* Nieuwe mogelijkheden: Multimodale taalmodellen kunnen veel meer dan alleen tekst verwerken. Ze kunnen bijvoorbeeld afbeeldingen herkennen, beschrijven, en zelf tekenen.
* Beter begrip: Door naar beelden te kijken, krijgen AI's een beter begrip van de wereld om ons heen. Dit helpt ze om taken beter uit te voeren.
* Handige toepassingen: Multimodale taalmodellen kunnen gebruikt worden voor allerlei handige toepassingen, zoals het herkennen van objecten op een foto, het genereren van bijschriften bij afbeeldingen, en nog veel meer.

# Nu jij:
Let op, deze prompt werkt niet in de workshop tool, enkel in the Gemini chat interface.
Probeer deze prompt thuis uit.

Kopieer de volgende prompt in https://gemini.google.com

    Genereer een photo van een unicorn die een ijsje eet. Het ijsje heeft de volgende smaken: aardbij, vanille, banaan.

Kopieer de volgende prompt in https://gemini.google.com

    Genereer een plaatje van een unicorn die een ijsje eet. Het ijsje heeft 3 bolletjes: aardbij, vanille, banaan. In South Park stijl.

Download dit plaatje (rechter muis, Opslaan als), en upload het in https://gemini.google.com (met het foto icoontje), kopieer daarna de volgende prompt:

![Kaart](map.png)

    Welk land op deze kaart is zichtbaar in het rood?